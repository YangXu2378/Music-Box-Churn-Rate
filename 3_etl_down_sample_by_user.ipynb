{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user id list and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use shell script to count unique id (large file, slow)\n",
    "import os\n",
    "cmd=\"\"\"\n",
    "export LC_CTYPE=C \n",
    "export LANG=C\n",
    "# get uid field| sort | count unique ids | strip blank spaces | output to file\n",
    "cat ../data/play/all_play_log| cut -f1 -d$'\\t'| sort | uniq -c | sed -e 's/^ *//g;s/ *$//g'> ../data/uid_count.csv\n",
    "\"\"\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/uid_count.csv',sep='\\s+', names=['count','uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 594735 entries, 0 to 594734\n",
      "Data columns (total 2 columns):\n",
      "count    594735 non-null int64\n",
      "uid      594734 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 9.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.947350e+05</td>\n",
       "      <td>5.947340e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.460525e+02</td>\n",
       "      <td>1.673628e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.526662e+04</td>\n",
       "      <td>1.047142e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.680262e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>1.684782e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.740000e+02</td>\n",
       "      <td>1.687685e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.501794e+06</td>\n",
       "      <td>1.692623e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count           uid\n",
       "count  5.947350e+05  5.947340e+05\n",
       "mean   2.460525e+02  1.673628e+08\n",
       "std    1.526662e+04  1.047142e+07\n",
       "min    1.000000e+00  0.000000e+00\n",
       "25%    9.000000e+00  1.680262e+08\n",
       "50%    4.000000e+01  1.684782e+08\n",
       "75%    1.740000e+02  1.687685e+08\n",
       "max    7.501794e+06  1.692623e+08"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove bots and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This statement allow to display plot without asking to\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5195.394000000553\n"
     ]
    }
   ],
   "source": [
    "top_count_threshold = np.percentile(df['count'],99.9)\n",
    "print(top_count_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of users: 594735\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of users:\",len(df['uid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove bots: get id with play counts<top_count_threshold\n",
    "id_list_bot_removed = np.array(df['uid'][df['count']<top_count_threshold].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of users after bot removed: 594139\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of users after bot removed:\",len(id_list_bot_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply downsample on uid level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample ids\n",
    "np.random.seed = 1\n",
    "down_sample_ratio = 0.1\n",
    "id_subset = set(id_list_bot_removed[np.random.random(id_list_bot_removed.shape)<down_sample_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of users after down sample: 59882\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of users after down sample:\",len(id_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define date conversion function\n",
    "import datetime\n",
    "def convert_date(s):\n",
    "    s = str(s).strip()\n",
    "    try:\n",
    "        year = int(s[:4])\n",
    "        month = int(s[4:6])\n",
    "        day = int(s[6:8])\n",
    "        return datetime.date(year,month,day)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#row processed: 1000000\n",
      "#row processed: 2000000\n",
      "#row processed: 3000000\n",
      "#row processed: 4000000\n",
      "#row processed: 5000000\n",
      "#row processed: 6000000\n",
      "#row processed: 7000000\n",
      "#row processed: 8000000\n",
      "#row processed: 9000000\n",
      "#row processed: 10000000\n",
      "#row processed: 11000000\n",
      "#row processed: 12000000\n",
      "#row processed: 13000000\n",
      "#row processed: 14000000\n",
      "#row processed: 15000000\n",
      "#row processed: 16000000\n",
      "#row processed: 17000000\n",
      "#row processed: 18000000\n",
      "#row processed: 19000000\n",
      "#row processed: 20000000\n",
      "#row processed: 21000000\n",
      "#row processed: 22000000\n",
      "#row processed: 23000000\n",
      "#row processed: 24000000\n",
      "#row processed: 25000000\n",
      "#row processed: 26000000\n",
      "#row processed: 27000000\n",
      "#row processed: 28000000\n",
      "#row processed: 29000000\n",
      "#row processed: 30000000\n",
      "#row processed: 31000000\n",
      "#row processed: 32000000\n",
      "#row processed: 33000000\n",
      "#row processed: 34000000\n",
      "#row processed: 35000000\n",
      "#row processed: 36000000\n",
      "#row processed: 37000000\n",
      "#row processed: 38000000\n",
      "#row processed: 39000000\n",
      "#row processed: 40000000\n",
      "#row processed: 41000000\n",
      "#row processed: 42000000\n",
      "#row processed: 43000000\n",
      "#row processed: 44000000\n",
      "#row processed: 45000000\n",
      "#row processed: 46000000\n",
      "#row processed: 47000000\n",
      "#row processed: 48000000\n",
      "#row processed: 49000000\n",
      "#row processed: 50000000\n",
      "#row processed: 51000000\n",
      "#row processed: 52000000\n",
      "#row processed: 53000000\n",
      "#row processed: 54000000\n",
      "#row processed: 55000000\n",
      "#row processed: 56000000\n",
      "#row processed: 57000000\n",
      "#row processed: 58000000\n",
      "#row processed: 59000000\n",
      "#row processed: 60000000\n",
      "#row processed: 61000000\n",
      "#row processed: 62000000\n",
      "#row processed: 63000000\n",
      "#row processed: 64000000\n",
      "#row processed: 65000000\n",
      "#row processed: 66000000\n",
      "#row processed: 67000000\n",
      "#row processed: 68000000\n",
      "#row processed: 69000000\n",
      "#row processed: 70000000\n",
      "#row processed: 71000000\n",
      "#row processed: 72000000\n",
      "#row processed: 73000000\n",
      "#row processed: 74000000\n",
      "#row processed: 75000000\n",
      "#row processed: 76000000\n",
      "#row processed: 77000000\n",
      "#row processed: 78000000\n",
      "#row processed: 79000000\n",
      "#row processed: 80000000\n",
      "#row processed: 81000000\n",
      "#row processed: 82000000\n",
      "#row processed: 83000000\n",
      "#row processed: 84000000\n",
      "#row processed: 85000000\n",
      "#row processed: 86000000\n",
      "#row processed: 87000000\n",
      "#row processed: 88000000\n",
      "#row processed: 89000000\n",
      "#row processed: 90000000\n",
      "#row processed: 91000000\n",
      "#row processed: 92000000\n",
      "#row processed: 93000000\n",
      "#row processed: 94000000\n",
      "#row processed: 95000000\n",
      "#row processed: 96000000\n",
      "#row processed: 97000000\n",
      "#row processed: 98000000\n",
      "#row processed: 99000000\n",
      "#row processed: 100000000\n",
      "#row processed: 101000000\n",
      "#row processed: 102000000\n",
      "#row processed: 103000000\n",
      "#row processed: 104000000\n",
      "#row processed: 105000000\n",
      "#row processed: 106000000\n",
      "#row processed: 107000000\n",
      "#row processed: 108000000\n",
      "#row processed: 109000000\n",
      "#row processed: 110000000\n",
      "#row processed: 111000000\n",
      "#row processed: 112000000\n",
      "#row processed: 113000000\n",
      "#row processed: 114000000\n",
      "#row processed: 115000000\n",
      "#row processed: 116000000\n",
      "#row processed: 117000000\n",
      "#row processed: 118000000\n",
      "#row processed: 119000000\n",
      "#row processed: 120000000\n",
      "#row processed: 121000000\n",
      "#row processed: 122000000\n",
      "#row processed: 123000000\n",
      "#row processed: 124000000\n",
      "#row processed: 125000000\n",
      "#row processed: 126000000\n",
      "#row processed: 127000000\n",
      "#row processed: 128000000\n",
      "#row processed: 129000000\n",
      "#row processed: 130000000\n",
      "#row processed: 131000000\n",
      "#row processed: 132000000\n",
      "#row processed: 133000000\n",
      "#row processed: 134000000\n",
      "#row processed: 135000000\n",
      "#row processed: 136000000\n",
      "#row processed: 137000000\n",
      "#row processed: 138000000\n",
      "#row processed: 139000000\n",
      "#row processed: 140000000\n",
      "#row processed: 141000000\n",
      "#row processed: 142000000\n",
      "#row processed: 143000000\n",
      "#row processed: 144000000\n",
      "#row processed: 145000000\n",
      "#row processed: 146000000\n"
     ]
    }
   ],
   "source": [
    "# down sample play by uid\n",
    "import csv\n",
    "input_file = '../data/play/all_play_log'\n",
    "output_file = '../data/play_ds.csv'\n",
    "input_field_list = ['uid','device','song_id','song_type','song_name','singer','play_time','song_length','paid_flag','date']\n",
    "output_field_list = ['uid','device','song_id','date','play_time','song_length']\n",
    "i=0\n",
    "with open(input_file,'r',encoding='latin-1') as fin, open(output_file,'w') as fout:\n",
    "    csvin = csv.DictReader(fin,delimiter='\\t',fieldnames=input_field_list,quoting=csv.QUOTE_NONE)\n",
    "    csvout = csv.writer(fout,delimiter=',')\n",
    "    csvout.writerow(output_field_list) # write header\n",
    "    for row in csvin:\n",
    "        i+=1\n",
    "        if i%1000000==0:\n",
    "            print(\"#row processed:\",i)\n",
    "        try:\n",
    "            int(row['uid'])\n",
    "        except:\n",
    "            continue\n",
    "        if int(row['uid']) in id_subset:\n",
    "            row['date'] = convert_date(row['date'])\n",
    "            if row['date'] != None: \n",
    "                csvout.writerow([str(row[key]).strip() for key in output_field_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample download by uid\n",
    "import csv\n",
    "input_file = '../data/down/all_down_log'\n",
    "output_file = '../data/down_ds.csv'\n",
    "input_field_list = ['uid','device','song_id','song_name','singer','paid_flag','date']\n",
    "output_field_list = ['uid','device','song_id','date']\n",
    "i=0\n",
    "with open(input_file,'r',encoding='latin-1') as fin, open(output_file,'w') as fout:\n",
    "    csvin = csv.DictReader(fin,delimiter='\\t',fieldnames=input_field_list,quoting=csv.QUOTE_NONE)\n",
    "    csvout = csv.writer(fout,delimiter=',')\n",
    "    csvout.writerow(output_field_list) # write header\n",
    "    for row in csvin:\n",
    "        i+=1\n",
    "        if i%1000000==0:\n",
    "            print(\"#row processed:\",i)\n",
    "        try:\n",
    "            int(row['uid'])\n",
    "        except:\n",
    "            continue\n",
    "        if int(row['uid']) in id_subset:\n",
    "            row['date'] = convert_date(row['date'])\n",
    "            if row['date'] != None: \n",
    "                csvout.writerow([str(row[key]).strip() for key in output_field_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample search by uid  \n",
    "import csv\n",
    "input_file = '../data/search/all_search_log'\n",
    "output_file = '../data/search_ds.csv'\n",
    "input_field_list = ['uid','device','time_stamp','search_query','date']\n",
    "output_field_list = ['uid','device','date']\n",
    "i=0\n",
    "with open(input_file,'r',encoding='latin-1') as fin, open(output_file,'w') as fout:\n",
    "    csvin = csv.DictReader(fin,delimiter='\\t',fieldnames=input_field_list,quoting=csv.QUOTE_NONE)\n",
    "    csvout = csv.writer(fout,delimiter=',')\n",
    "    csvout.writerow(output_field_list) # write header\n",
    "    for row in csvin:\n",
    "        i+=1\n",
    "        if i%1000000==0:\n",
    "            print(\"#row processed:\",i)\n",
    "        try:\n",
    "            int(row['uid'])\n",
    "        except:\n",
    "            continue\n",
    "        if int(row['uid']) in id_subset:\n",
    "            row['date'] = convert_date(row['date'])\n",
    "            if row['date'] != None: \n",
    "                csvout.writerow([str(row[key]).strip() for key in output_field_list])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create event table for feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing play ...\n",
      "Processing down ...\n",
      "Processing search ...\n"
     ]
    }
   ],
   "source": [
    "play_file = '../data/play_ds.csv'\n",
    "down_file = '../data/down_ds.csv'\n",
    "search_file = '../data/search_ds.csv'\n",
    "output_file = '../data/event_ds.csv'\n",
    "play_field_list = ['uid','device','song_id','date','play_time','song_length']\n",
    "down_field_list = ['uid','device','song_id','date']\n",
    "search_field_list = ['uid','device','date']\n",
    "output_field_list = ['uid','event','song_id','date']\n",
    "with open(play_file,'r') as f_play, open(down_file,'r') as f_down, \\\n",
    "open(search_file,'r') as f_search,open(output_file,'w') as f_out:\n",
    "    csvplay = csv.DictReader(f_play,delimiter=',')\n",
    "    csvdown = csv.DictReader(f_down,delimiter=',')\n",
    "    csvsearch = csv.DictReader(f_search,delimiter=',')\n",
    "    csvout = csv.writer(f_out,delimiter=',')\n",
    "    csvout.writerow(output_field_list) # write header\n",
    "    print('Processing play ...')\n",
    "    for row in csvplay:\n",
    "        row['event'] = 'P'\n",
    "        row['date']\n",
    "        csvout.writerow([row[key] for key in output_field_list])\n",
    "    print('Processing down ...')\n",
    "    for row in csvdown:\n",
    "        row['event'] = 'D'\n",
    "        csvout.writerow([row[key] for key in output_field_list])\n",
    "    print('Processing search ...')\n",
    "    for row in csvsearch:\n",
    "        row['event'] = 'S'\n",
    "        csvout.writerow([row.get(key,'') for key in output_field_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
